{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "from skimage.util import random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def noise(array):\n",
    "#     \"\"\"\n",
    "#     Adds random noise to each image in the supplied array.\n",
    "#     \"\"\"\n",
    "\n",
    "#     noise_factor = 0.1\n",
    "#     noisy_array = array + noise_factor * np.random.normal(\n",
    "#         loc=0.0, scale=1.0, size=array.shape\n",
    "#     )\n",
    "\n",
    "#     return np.clip(noisy_array, 0.0, 1.0)\n",
    "import random\n",
    "\n",
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noise_factor = random.randrange(0, 40)/100\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    array = np.clip(noisy_array, 0.0, 1.0)\n",
    "   \n",
    "    std = random.randrange(0, 40)/100\n",
    "\n",
    "    noisy_images = [img + np.random.normal(0, std, img.shape) for img in array]\n",
    "\n",
    "    return noisy_images\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, 300)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "IMAGE_TARGET_SIZE = (5, 1400, 1)\n",
    "BATCH_SIZE =  128\n",
    "\n",
    "from morse_helpers import create_sets\n",
    "from morse_label_funcs import  labels_to_one_hot_positions_categorical, letter_n_to_one_hot_positions_categorical, position_regression\n",
    "\n",
    "\n",
    "def get_sets():\n",
    "    return [\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_000/\", 'wordsMatrices_04_000', \"Words_04_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_100/\", 'wordsMatrices_04_100', \"Words_04_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_200/\", 'wordsMatrices_04_200', \"Words_04_200.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_210/\", 'wordsMatrices_04_210', \"Words_04_210.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_220/\", 'wordsMatrices_04_220', \"Words_04_220.csv\"],\n",
    "\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_000/\", 'wordsMatrices_11_000', \"Words_11_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_100/\", 'wordsMatrices_11_100', \"Words_11_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_200/\", 'wordsMatrices_11_200', \"Words_11_200.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_210/\", 'wordsMatrices_11_210', \"Words_11_210.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_220/\", 'wordsMatrices_11_220', \"Words_11_220.csv\"],\n",
    "\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_000/\", 'wordsMatrices_06_000', \"Words_06_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_100/\", 'wordsMatrices_06_100', \"Words_06_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_200/\", 'wordsMatrices_06_200', \"Words_06_200.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_210/\", 'wordsMatrices_06_210', \"Words_06_210.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_220/\", 'wordsMatrices_06_220', \"Words_06_220.csv\"],\n",
    "\n",
    "        [\"./training_data/MorseTrainSet_13/GEN13_VER_000/\", 'wordsMatrices_13_000', \"Words_13_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_13/GEN13_VER_100/\", 'wordsMatrices_13_100', \"Words_13_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_13/GEN13_VER_200/\", 'wordsMatrices_13_200', \"Words_13_200.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_13/GEN13_VER_210/\", 'wordsMatrices_13_210', \"Words_13_210.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_13/GEN13_VER_220/\", 'wordsMatrices_13_220', \"Words_13_220.csv\"],\n",
    "\n",
    "    ]\n",
    "\n",
    "(image_fnames, morse_labels) = create_sets(\n",
    "    get_sets(), \n",
    "    IMAGE_TARGET_SIZE,\n",
    "    [position_regression, letter_n_to_one_hot_positions_categorical],\n",
    "    letter_n=1,\n",
    "    overwrite_images=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat label arrays\n",
    "morse_labels_concat = np.array([morse_labels[0], morse_labels[1].astype(\"int\")]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import create_all_sets\n",
    "\n",
    "TEST_SPLIT_SIZE = 0.80\n",
    "VALIDATION_SPLIT_SIZE = 0.90\n",
    "\n",
    "train, labels, train_validation, labels_validation, train_test, labels_test = create_all_sets(\n",
    "    image_fnames, morse_labels_concat, TEST_SPLIT_SIZE, VALIDATION_SPLIT_SIZE, shuffle_before_test_split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import convert_image_to_array\n",
    "class Image_Generator_AutoEncoder(keras.utils.Sequence) :\n",
    "    \n",
    "    def __init__(self, image_filenames, labels, batch_size, image_target_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.image_target_size = image_target_size\n",
    "        # self.image_prepocessors = image_prepocessors\n",
    "        # self.label_func = label_func\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "\n",
    "    def __get_labels__(self, idx): \n",
    "         batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "         return batch_y\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        train_image_lists = []\n",
    "        for img_name in batch_x:\n",
    "            img = convert_image_to_array(img_name, self.image_target_size)\n",
    "            train_image_lists.append(img)\n",
    "\n",
    "        n = random.randint(0, 20)\n",
    "        train_image_lists = [np.pad(img, [(0,0),(n,0), (0,0)], mode='constant')[:, :1400] for img in train_image_lists]\n",
    "\n",
    "        noisy = noise(np.array(train_image_lists))\n",
    "\n",
    "        arrays = np.array(noisy)[:,0:-1, :1400] , np.array(train_image_lists)[:,0:-1, :1400]\n",
    "        return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import add_zeropad_random\n",
    "\n",
    "image_prepocessors = [{\"func\" :add_zeropad_random, \"params\": [-10, 15]}]\n",
    "\n",
    "training_batch_generator = Image_Generator_AutoEncoder(train, labels, BATCH_SIZE, IMAGE_TARGET_SIZE)\n",
    "validation_batch_generator = Image_Generator_AutoEncoder(train_validation, labels_validation, BATCH_SIZE, IMAGE_TARGET_SIZE)\n",
    "\n",
    "# t, l = training_batch_generator.__getitem__(0)\n",
    "\n",
    "\n",
    "# for i in range(5):\n",
    "#     show_image(t[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(4, 1400, 1))\n",
    "\n",
    "# cropped = keras.layers.Cropping2D(cropping=((0, 1), (0,0)), data_format=None)(input)\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(70, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(70, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((1, 2), padding=\"same\")(x)\n",
    "\n",
    "# x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(70, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((1, 2), padding=\"same\")(x)\n",
    "\n",
    "# x = layers.BatchNormalization()(x)\n",
    "\n",
    "# Decoder\n",
    "\n",
    "x = layers.Conv2D(70, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((1, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(70, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((1, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(70, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "# x = layers.Conv2DTranspose(32, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input, x)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"mean_squared_error\"])\n",
    "autoencoder.summary()\n",
    "\n",
    "init_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = autoencoder.predict(test_data)\n",
    "# display(test_data, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.fit(\n",
    "#     x=noisy_train_data,\n",
    "#     y=train_data,\n",
    "#     epochs=10,\n",
    "#     batch_size=128,\n",
    "#     shuffle=True,\n",
    "#     validation_data=(noisy_test_data, test_data),\n",
    "# )\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "def fit_model(epochs):\n",
    "\t\n",
    "\tglobal init_epoch\n",
    "\thistory = autoencoder.fit(\n",
    "\t\t\t\t\t   training_batch_generator,\n",
    "\t                   steps_per_epoch = int(len(train) // BATCH_SIZE),\n",
    "\t                   epochs = epochs + init_epoch,\n",
    "\t\t\t\t\t   initial_epoch=init_epoch,\n",
    "\t                   verbose =1,\n",
    "\t                   validation_data = validation_batch_generator,\n",
    "\t                   validation_steps = int(len(train_validation) // BATCH_SIZE))\n",
    "\t\n",
    "\tinit_epoch += epochs\n",
    "\treturn history\n",
    "\n",
    "history = fit_model(NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import Image_Generator\n",
    "\n",
    "\n",
    "def add_noise(params):\n",
    "    def add_noise(train_images, lbls, image_target_size):\n",
    "        train_images = np.array(train_images)\n",
    "        noise_factor = 0.20\n",
    "        noisy_array = train_images + noise_factor * np.random.normal(\n",
    "            loc=0.0, scale=1.0, size=train_images.shape\n",
    "        )\n",
    "\n",
    "        array = np.clip(noisy_array, 0.0, 1.0)\n",
    "    \n",
    "        std = 0.2\n",
    "        noisy_images = [img + np.random.normal(0, std, img.shape) for img in array]\n",
    "\n",
    "        return (noisy_images, lbls)\n",
    "    \n",
    "    return add_noise\n",
    "\n",
    "\n",
    "def labels_to_one_hot(lbls_pos, lbls_letters):\n",
    "    label_letters = lbls_letters.astype(\"int\")\n",
    "    # clean up magic numbers\n",
    "    labels_one_hot = np.zeros((label_letters.size, 26))\n",
    "    labels_one_hot[np.arange(label_letters.size),label_letters] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def cut(params):\n",
    "    def cut_and_center(train_images, lbls, image_target_size):\n",
    "\n",
    "        cut_images = []\n",
    "        # train_images = train_images.copy()\n",
    "\n",
    "        for i in range(len(train_images)):\n",
    "            train_images[i][:, int(lbls[i] * 1400) + 3:] = 0\n",
    "            padding = int(150 / 2)  - int((int(lbls[i] *1400) + 3) / 2)\n",
    "            train_image_padded = np.pad(train_images[i], [(0,0),(padding,0), (0,0)], mode='constant')[:, :1400]\n",
    "            cut_images.append(train_image_padded)\n",
    "\n",
    "        return (cut_images, lbls)\n",
    "    return cut_and_center\n",
    "\n",
    "def add_zeros_row(params):\n",
    "    def add_zeros(train_images, lbls, image_target_size):\n",
    "        z = np.zeros(1400)\n",
    "        zreshape = z.reshape(1, 1400, 1)\n",
    "        zadded = []\n",
    "        for img in train_images:\n",
    "            \n",
    "            zadded.append(np.vstack((img, zreshape)))\n",
    "        \n",
    "        return (np.array(zadded), lbls)\n",
    "\n",
    "    return add_zeros\n",
    "\n",
    "def autoencode_array(params):\n",
    "    def autoencode_array(train_images, lbls, image_target_size):\n",
    "\n",
    "        autoencoded = autoencoder.predict(np.array(train_images))\n",
    "        \n",
    "        return  (autoencoded, lbls)\n",
    "\n",
    "    return autoencode_array\n",
    "\n",
    "def shrink_image(params):\n",
    "    def shrink_image(train_images, lbls, image_target_size):\n",
    "        \n",
    "        return  (np.array(train_images)[:,0:-1, :1400], lbls)\n",
    "\n",
    "    return shrink_image\n",
    "\n",
    "\n",
    "image_prepocessors = [\n",
    "    {\"func\" :add_noise, \"params\": \"\"}, \n",
    "    {\"func\" :shrink_image, \"params\": \"\"},  \n",
    "    {\"func\" :autoencode_array, \"params\": \"\"},\n",
    "    {\"func\" :add_zeros_row, \"params\": \"\"}, \n",
    "    {\"func\" :cut, \"params\": \"\"}\n",
    "]\n",
    "test_batch_generator_categories = Image_Generator(train_test, labels_test, BATCH_SIZE, IMAGE_TARGET_SIZE, image_prepocessors, labels_to_one_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_3 = tf.keras.models.load_model(\"saved_model_3\")\n",
    "\n",
    "loaded_model_3.evaluate(test_batch_generator_categories, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, l = test_batch_generator_categories.__getitem__(0)\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    show_image(t[i])\n",
    "    print(l[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddce95701716284d8751d5796858f7ca5e76f20d028bc4aeb8f12865d04c55c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('newenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
