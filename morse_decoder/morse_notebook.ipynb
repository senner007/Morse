{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Conv2D, Conv1D, MaxPooling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras, config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs Available: \", len(config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "IMAGE_TARGET_SIZE = (5, 1400, 1)\n",
    "BATCH_SIZE =  128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from morse_helpers import create_sets\n",
    "from morse_label_funcs import  labels_to_one_hot_positions_categorical, letter_n_to_one_hot_positions_categorical, position_regression\n",
    "\n",
    "\n",
    "def get_sets():\n",
    "    return [\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_000/\", 'wordsMatrices_04_000', \"Words_04_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_100/\", 'wordsMatrices_04_100', \"Words_04_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_200/\", 'wordsMatrices_04_200', \"Words_04_200.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_210/\", 'wordsMatrices_04_210', \"Words_04_210.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_04/GEN04_VER_220/\", 'wordsMatrices_04_220', \"Words_04_220.csv\"],\n",
    "\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_000/\", 'wordsMatrices_11_000', \"Words_11_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_100/\", 'wordsMatrices_11_100', \"Words_11_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_200/\", 'wordsMatrices_11_200', \"Words_11_200.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_210/\", 'wordsMatrices_11_210', \"Words_11_210.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_11/GEN11_VER_220/\", 'wordsMatrices_11_220', \"Words_11_220.csv\"],\n",
    "\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_000/\", 'wordsMatrices_06_000', \"Words_06_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_100/\", 'wordsMatrices_06_100', \"Words_06_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_200/\", 'wordsMatrices_06_200', \"Words_06_200.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_210/\", 'wordsMatrices_06_210', \"Words_06_210.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_06/GEN06_VER_220/\", 'wordsMatrices_06_220', \"Words_06_220.csv\"],\n",
    "\n",
    "        # [\"./training_data/MorseTrainSet_13/GEN13_VER_000/\", 'wordsMatrices_13_000', \"Words_13_000.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_13/GEN13_VER_100/\", 'wordsMatrices_13_100', \"Words_13_100.csv\"],\n",
    "        # [\"./training_data/MorseTrainSet_13/GEN13_VER_200/\", 'wordsMatrices_13_200', \"Words_13_200.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_13/GEN13_VER_210/\", 'wordsMatrices_13_210', \"Words_13_210.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_13/GEN13_VER_220/\", 'wordsMatrices_13_220', \"Words_13_220.csv\"],\n",
    "\n",
    "    ]\n",
    "\n",
    "(image_fnames, morse_labels) = create_sets(\n",
    "    get_sets(), \n",
    "    IMAGE_TARGET_SIZE,\n",
    "    [position_regression, letter_n_to_one_hot_positions_categorical],\n",
    "    letter_n=1,\n",
    "    overwrite_images=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat label arrays\n",
    "morse_labels_concat = np.array([morse_labels[0], morse_labels[1].astype(\"int\")]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve me\n",
    "def labels_to_one_hot(lbls, image_target_size = None):\n",
    "    assert type(lbls[0]) == np.float64\n",
    "    label_letters = lbls.astype(\"int\")\n",
    "    # clean up magic numbers\n",
    "    labels_one_hot = np.zeros((label_letters.size, 26))\n",
    "    labels_one_hot[np.arange(label_letters.size),label_letters] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import create_all_sets\n",
    "\n",
    "TEST_SPLIT_SIZE = 0.80\n",
    "VALIDATION_SPLIT_SIZE = 0.90\n",
    "\n",
    "train, labels, train_validation, labels_validation, train_test, labels_test = create_all_sets(\n",
    "    image_fnames, morse_labels_concat, TEST_SPLIT_SIZE, VALIDATION_SPLIT_SIZE, shuffle_before_test_split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import Image_Generator, add_zeropad_random, add_noise_random, return_label_positions\n",
    "\n",
    "image_prepocessors = [{\"func\" :add_zeropad_random, \"params\": [-10, 15]}, {\"func\": add_noise_random, \"params\": [0, 20]}]\n",
    "\n",
    "training_batch_generator = Image_Generator(train, labels, BATCH_SIZE, IMAGE_TARGET_SIZE, image_prepocessors, return_label_positions)\n",
    "validation_batch_generator = Image_Generator(train_validation, labels_validation, BATCH_SIZE, IMAGE_TARGET_SIZE, image_prepocessors, return_label_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_addblock(x, kernelsize, filters):\n",
    "    fx = layers.Conv2D(filters, kernelsize, activation='relu', padding='same')(x)\n",
    "    fx = layers.BatchNormalization()(fx)\n",
    "    fx = layers.Conv2D(filters, kernelsize, padding='same')(fx)\n",
    "    out = layers.Add()([x,fx])\n",
    "    out = layers.ReLU()(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_pos(input_layer):\n",
    "    cropped = keras.layers.Cropping2D(cropping=((0, 0), (0,1250)), data_format=None)(input_layer)\n",
    "\n",
    "    conv1           = Conv2D(90,(1,7), padding=\"same\",activation=\"relu\")(cropped)\n",
    "    pool1           = MaxPooling2D(pool_size=(2,1),padding=\"same\")(conv1)\n",
    "\n",
    "    conv2           = Conv2D(90,(1,7),padding=\"same\",activation=\"relu\")(pool1)\n",
    "    pool2           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv2)\n",
    "\n",
    "    conv3           = Conv2D(90,(1,5),padding=\"same\",activation=\"relu\")(pool2)\n",
    "    pool3           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv3)\n",
    "\n",
    "    conv4           = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(pool3)\n",
    "    pool4           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv4)\n",
    "\n",
    "    conv5           = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(pool4)\n",
    "    pool5           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv5)\n",
    "\n",
    "    conv6           = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(pool5)\n",
    "    pool6           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv6)\n",
    "\n",
    "    conv7           = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(pool6)\n",
    "    pool7           = MaxPooling2D(pool_size=(1,2),padding=\"same\")(conv7)\n",
    "\n",
    "    flat            = Flatten()(pool7)\n",
    "\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_layer    = Input(shape=IMAGE_TARGET_SIZE)\n",
    "\n",
    "flat_position = conv_model_pos(input_layer)\n",
    "\n",
    "output_layer_position    = Dense(1, name=\"regr\")(flat_position)\n",
    "model           = Model(inputs=input_layer, outputs=output_layer_position)\n",
    "model.compile(loss=[\"mse\"], optimizer='adam', metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "init_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "def fit_model(epochs):\n",
    "\t\n",
    "\tglobal init_epoch\n",
    "\thistory = model.fit(\n",
    "\t\t\t\t\t   training_batch_generator,\n",
    "\t                   steps_per_epoch = int(len(train) // BATCH_SIZE),\n",
    "\t                   epochs = epochs + init_epoch,\n",
    "\t\t\t\t\t   initial_epoch=init_epoch,\n",
    "\t                   verbose =1,\n",
    "\t                   validation_data = validation_batch_generator,\n",
    "\t                   validation_steps = int(len(train_validation) // BATCH_SIZE))\n",
    "\t\n",
    "\t\n",
    "\tinit_epoch += epochs\n",
    "\treturn history\n",
    "\n",
    "history = fit_model(NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    fig = plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, 300)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "positions_above_px = 3\n",
    "\n",
    "def get_deviating_predictions(positions_above_px, generator, predictions):\n",
    "    regression_differences = []\n",
    "    indexer = 0\n",
    "\n",
    "    for imgs_batch, labels_batch in generator:\n",
    "\n",
    "        for i in range(len(imgs_batch)):\n",
    "\n",
    "            regr_pred = predictions[indexer] * IMAGE_TARGET_SIZE[1]\n",
    "            regr_test_label = labels_batch[i] * IMAGE_TARGET_SIZE[1]\n",
    "\n",
    "            if abs(regr_pred[0] - regr_test_label) > positions_above_px:\n",
    "                regression_differences.append([regr_pred, regr_test_label, imgs_batch[i]])\n",
    "\n",
    "            indexer += 1\n",
    "\n",
    "    return regression_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : print model summary, model history, image optimizers, training sets used, plot graphs, save to pdf\n",
    "\n",
    "def print_noise_results(predictions, noise_level, positions_above_px, differences, evaluations):\n",
    "    print(\"Total predictions:\", len(predictions))\n",
    "    print(\"Noise level:\", noise_level)\n",
    "    print(\"Total position predictions off by more than pixels:\", positions_above_px, \":\", len(differences))\n",
    "    print(\"Position predictions percentage incorrect:\", round( (len(differences) / len(predictions) * 100), 4), \"%\")\n",
    "    print(\"Model evaluation:\", evaluations)\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from morse_helpers import add_noise, add_noise_random\n",
    "import inspect\n",
    "\n",
    "# TODO : create json report instead\n",
    "\n",
    "print(\"\\nData sets used:\")\n",
    "print(inspect.getsource(get_sets))\n",
    "\n",
    "print(\"\\nData size:\")\n",
    "print(\"Training set size:\", len(train))\n",
    "print(\"Validation set size:\", len(train_validation))\n",
    "print(\"Test set size:\", len(train_test))\n",
    "\n",
    "print(\"\\nImage pre-processors used:\")\n",
    "print(image_prepocessors)\n",
    "\n",
    "print(\"\\nConvolution layer:\")\n",
    "print(inspect.getsource(conv_model_pos))\n",
    "\n",
    "print(\"\\nModel summary:\")\n",
    "print(model.summary())\n",
    "\n",
    "print(\"\\nModel performance:\")\n",
    "print(history.history)\n",
    "\n",
    "print(\"\\nTotal epochs:\", init_epoch)\n",
    "\n",
    "#Print results\n",
    "print(\"\\nResults:\")\n",
    "noise_levels = [0.1, 0.2, 0.3]\n",
    "for noise_level in noise_levels:\n",
    "\n",
    "    test_batch_generator = Image_Generator(train_test, labels_test, BATCH_SIZE, IMAGE_TARGET_SIZE, [{\"func\": add_noise, \"params\": noise_level}], return_label_positions)\n",
    "    predictions = model.predict(test_batch_generator)\n",
    "    regression_differences  = get_deviating_predictions(positions_above_px, test_batch_generator, predictions)\n",
    "    evaluations = model.evaluate(test_batch_generator, verbose = 0)\n",
    "\n",
    "    print_noise_results(predictions, noise_level, positions_above_px, regression_differences, evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "with open('results/results.txt' + timestr, 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0   \n",
    "for diff in regression_differences:\n",
    "\n",
    "    counter += 1\n",
    "    if counter > 10:\n",
    "        break\n",
    "\n",
    "    pred, correct, img = diff\n",
    "\n",
    "    img_pred = img.copy()\n",
    "    img_correct = img.copy()\n",
    "\n",
    "    print('Prediction', round(pred[0]))\n",
    "    img_pred[:, round(int(pred))] = 1\n",
    "    show_image(img_pred)\n",
    "\n",
    "    print('Correct', round(correct))\n",
    "    img_correct[:, round(int(correct))] = 1\n",
    "    show_image(img_correct)\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf as mpt\n",
    "\n",
    "def right_roll_image_by_n(img, roll_value_n):\n",
    "    return np.roll(img, roll_value_n, axis=1)\n",
    "\n",
    "def get_label_prediction(img, model, img_width): \n",
    "    x_right_rolled_exp_dim = np.expand_dims(img, axis=0)\n",
    "    single_predict = model.predict(x_right_rolled_exp_dim)\n",
    "    return single_predict[0] * img_width\n",
    "\n",
    "\n",
    "def roll_and_display_img(img, indexer):\n",
    "\n",
    "    image_right_rolled = right_roll_image_by_n(img, int(-10 + (indexer / 5)))\n",
    "\n",
    "    label_prediction = get_label_prediction(image_right_rolled, model, IMAGE_TARGET_SIZE[1])\n",
    "\n",
    "    # Draw vertical line\n",
    "    image_right_rolled[:, int(label_prediction)] = 1\n",
    "\n",
    "    fig = show_image(image_right_rolled)\n",
    "    pdf.savefig( fig )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%capture \n",
    "# # capture means suppress output\n",
    "\n",
    "# pdf = mpt.PdfPages(\"single_predictions_rolled_randomly.pdf\")\n",
    "\n",
    "# single_image_batch, single_label_batch = test_batch_generator.__getitem__(0)\n",
    "\n",
    "# for i in range(len(single_image_batch)):\n",
    "#     roll_and_display_img(single_image_batch[i], i)\n",
    "    \n",
    "# pdf.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddce95701716284d8751d5796858f7ca5e76f20d028bc4aeb8f12865d04c55c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('newenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
