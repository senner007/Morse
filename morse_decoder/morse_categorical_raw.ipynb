{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Conv2D, Conv1D, MaxPooling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras, config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs Available: \", len(config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from image_process.image_preprocessors import add_noise, add_noise_randomly, shift_random_update_positions, shift_randomly_position_labels, cut_and_right_align_raw\n",
    "from data_filters import tempo_interval, take_percent\n",
    "# Global settings\n",
    "TEST_SPLIT_SIZE = 0.80\n",
    "VALIDATION_SPLIT_SIZE = 0.90\n",
    "IMAGE_TARGET_SIZE = (5, 1400, 1)\n",
    "BATCH_SIZE = 128\n",
    "EPOCH_SIZE = 500\n",
    "IMAGE_CROP_END_WIDTH = 1250\n",
    "IMAGE_CROPPED_WIDTH = IMAGE_TARGET_SIZE[1] - IMAGE_CROP_END_WIDTH\n",
    "BATCH_SIZE =  128\n",
    "CATEGORIES = 26\n",
    "LETTER_END_POSITION = \"P1\"\n",
    "ADD_NOISE_RANDOMLY = [-2, 30]\n",
    "ADD_SIGNAL_INDENT_RANDOMLY = [12860, 12860]\n",
    "SHIFT_MIN_MAX = [-200, -140]\n",
    "IMAGE_PREPOCESSORS = [\n",
    "    {\"func\": shift_randomly_position_labels, \"params\" : SHIFT_MIN_MAX},\n",
    "    {\"func\": cut_and_right_align_raw, \"params\" : IMAGE_CROPPED_WIDTH },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, width, position = 0):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, width)\n",
    "    if position != 0:\n",
    "        plt.xticks(position)    \n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Image_Generator_helpers import  DataSets, set_paths, global_path, Random_Item\n",
    "from data_filters import tempo_interval_raw\n",
    "from morse_label_funcs import code_number\n",
    "set_obj: DataSets = DataSets(set_paths, global_path, [tempo_interval_raw([18, 25])])\n",
    "set_obj.csv_files\n",
    "\n",
    "shift_max = abs(SHIFT_MIN_MAX[0] - SHIFT_MIN_MAX[1])\n",
    "print(shift_max)\n",
    "\n",
    "def labels_to_one_hot(labels):\n",
    "    labels_one_hot = np.zeros((labels.size, CATEGORIES))\n",
    "    labels_one_hot[np.arange(labels.size),labels] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def get_position_labels(random_items):\n",
    "    return [item.csv_row[LETTER_END_POSITION].values.astype(np.float64)[0] for item in random_items]\n",
    "\n",
    "def position_labels_post_process(labels, set_obj: DataSets, random_items: list[Random_Item]):\n",
    "    label_letters = np.array([code_number.index(item.csv_row[\"WORD\"].apply(str).values[0][0].lower()) for item in random_items])\n",
    "    return labels_to_one_hot(label_letters)\n",
    "\n",
    "def position_labels_de_normalizer(labels, set_obj: DataSets, random_items: list[Random_Item]):\n",
    "    return np.array([(label * (set_obj.max_first_letter_position + shift_max - set_obj.min_first_letter_position) + set_obj.min_first_letter_position) for label in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_generators.image_generator import Image_Generator_RAW\n",
    "Train_Generator_RAW = Image_Generator_RAW(\n",
    "    image_amount=BATCH_SIZE * EPOCH_SIZE,\n",
    "    set_obj= set_obj,\n",
    "    FFT_JUMP=64,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_target_size=IMAGE_TARGET_SIZE,\n",
    "    image_prepocessors=IMAGE_PREPOCESSORS,\n",
    "    noise_range=ADD_NOISE_RANDOMLY,\n",
    "    random_signal_indent=ADD_SIGNAL_INDENT_RANDOMLY,\n",
    "    label_func = get_position_labels,\n",
    "    label_post_process=position_labels_post_process\n",
    "    )\n",
    "\n",
    "t, l = Train_Generator_RAW.__getitem__(0)\n",
    "\n",
    "\n",
    "for idx,img in enumerate(t):\n",
    "    print(\"label: \")\n",
    "    label = l[idx]\n",
    "    print(label)\n",
    "    show_image(img, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual block\n",
    "def get_addblock(x, kernelsize, filters):\n",
    "    fx = layers.Conv2D(filters, kernelsize, activation='relu', padding='same')(x)\n",
    "    fx = layers.BatchNormalization()(fx)\n",
    "    fx = layers.Conv2D(filters, kernelsize, padding='same')(fx)\n",
    "    out = layers.Add()([x,fx])\n",
    "    out = layers.ReLU()(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_catg(input_layer):\n",
    "    \n",
    "    # x = keras.layers.Cropping2D(cropping=((0, 0), (0,IMAGE_CROP_END_WIDTH)), data_format=None)(input_layer)\n",
    "\n",
    "    x = get_addblock(input_layer, (3,5), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "    x = get_addblock(x, (3,7), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "    x = get_addblock(x, (3,3), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "    x = get_addblock(x, (3,3), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "  \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_layer    = Input(shape=(5, 150, 1))\n",
    "conv_model_flattened = conv_model_catg(input_layer)\n",
    "output_layer_letter    = Dense(CATEGORIES, activation=\"softmax\")(conv_model_flattened)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer_letter)\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "\n",
    "def fit_model(epochs):\n",
    "\t\n",
    "\tglobal init_epoch\n",
    "\thistory = model.fit(\n",
    "\t\tTrain_Generator_RAW,\n",
    "\t\tsteps_per_epoch = EPOCH_SIZE,\n",
    "\t\tepochs = epochs + init_epoch,\n",
    "\t\tinitial_epoch=init_epoch,\n",
    "\t\tverbose =1,\n",
    "\t\t# validation_data = validation_batch_generator,\n",
    "\t\t# validation_steps = int(len(train_validation) // BATCH_SIZE),\n",
    "\t\tworkers=12,\n",
    "\t\tuse_multiprocessing=True\n",
    "\t)\n",
    "\n",
    "\t\n",
    "\tinit_epoch += epochs\n",
    "\treturn history\n",
    "\n",
    "history = fit_model(num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_difference = 3\n",
    "def sum_up_to(generator):\n",
    "    return generator.__getitem__(0)\n",
    "\n",
    "\n",
    "def get_deviating_predictions(pixel_difference, generator):\n",
    "\n",
    "    a_pool = Pool()\n",
    "\n",
    "    result = a_pool.map(sum_up_to, [generator for a in range(generator.__len__())])\n",
    "\n",
    "    categorical_differences = []\n",
    "\n",
    "    for imgs_batch, labels_batch in result:\n",
    "\n",
    "        predictions = model.predict_on_batch(imgs_batch) ## make the predictions before the loop, then insert predictions into multiprocessing functions\n",
    "     \n",
    "        for i in range(len(imgs_batch)):\n",
    "\n",
    "            catg_pred = np.argmax(predictions[i])\n",
    "            catg_test_label = np.argmax(labels_batch[i])\n",
    "\n",
    "            if catg_pred != catg_test_label:\n",
    "                categorical_differences.append([catg_pred, catg_test_label, imgs_batch[i]])\n",
    "\n",
    "    return categorical_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from training_log import Training_Data_Log, print_name, json_to_file\n",
    "import inspect\n",
    "\n",
    "data_log = Training_Data_Log()\n",
    "data_log.model_config = model.to_json()\n",
    "# data_log.model_config_method_string = [inspect.getsource(conv_model_position)]\n",
    "# data_log.training_sets = get_sets()\n",
    "# data_log.training_set_size = len(train)\n",
    "# data_log.validation_set_size = len(train_validation)\n",
    "# data_log.test_set_size = len(train_test)\n",
    "data_log.image_pre_processors = print_name(IMAGE_PREPOCESSORS)\n",
    "data_log.noise_added = ADD_NOISE_RANDOMLY\n",
    "# data_log.training_data_masks = print_name(MASKS)\n",
    "data_log.model_summary = model.summary()\n",
    "data_log.model_optimizer = str(type(model.optimizer))\n",
    "data_log.model_history = history.history\n",
    "data_log.model_history_final_epoch = {k: v[-1] for k, v in history.history.items()}\n",
    "data_log.total_epochs = init_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression_Results:\n",
    "    image_preprocessors_test = None\n",
    "    total_predictions = None\n",
    "    noise_level = None\n",
    "    difference_in_pixels = None\n",
    "    predictions_off_by_more_than_difference = None\n",
    "    predictions_incorrect_prercent = None\n",
    "    model_evaluation = None\n",
    "\n",
    "noise_levels = [0.0]\n",
    "result_array = []\n",
    "batches = 200\n",
    "for noise_level in noise_levels:\n",
    "\n",
    "    test_batch_generator = Train_Generator_RAW = Image_Generator_RAW(\n",
    "        image_amount=BATCH_SIZE * batches,\n",
    "        set_obj= set_obj,\n",
    "        FFT_JUMP=64,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        image_target_size=IMAGE_TARGET_SIZE,\n",
    "        image_prepocessors=IMAGE_PREPOCESSORS,\n",
    "        noise_range=ADD_NOISE_RANDOMLY,\n",
    "        random_signal_indent=ADD_SIGNAL_INDENT_RANDOMLY,\n",
    "        label_func = get_position_labels,\n",
    "        label_post_process=position_labels_post_process\n",
    "    )\n",
    "\n",
    "\n",
    "    categorical_differences = get_deviating_predictions(pixel_difference, test_batch_generator)\n",
    "    evaluations = model.evaluate(test_batch_generator, verbose = 0)\n",
    "\n",
    "    results = Regression_Results()\n",
    "    # results.image_preprocessors_test = print_name(image_preprocessors_test)\n",
    "    results.total_predictions = batches * BATCH_SIZE\n",
    "    # results.noise_level = noise_level\n",
    "    results.predictions_incorrect = len(categorical_differences)\n",
    "    results.predictions_incorrect_prercent = round( (  len(categorical_differences) / (batches * BATCH_SIZE)  ) * 100, 4)\n",
    "    results.model_evaluation = evaluations\n",
    "\n",
    "    result_array.append(results.__dict__)\n",
    "\n",
    "    print(len(categorical_differences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log.results = result_array\n",
    "print(data_log.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_file(\"logs/categorical/categorical_data_log\", data_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"saved_model_categorical_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_label_funcs import code_number\n",
    "print(\"Incorrect predictions:\")\n",
    "print(\"----------------------------------------------------------------------------------------\")\n",
    "for idx, diff in enumerate(categorical_differences):\n",
    "\n",
    "    if idx > 5:\n",
    "        break\n",
    "\n",
    "    pred, correct, img = diff\n",
    "\n",
    "    print('Prediction:', pred, code_number[pred])\n",
    "    print('Correct:', correct, code_number[correct])\n",
    "    show_image(img, 150)\n",
    "    print(\"----------------------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be0503bf1d8a1ee3ca0077be831d95fbcddd9686f11808f41fa1809452b7e6ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
