{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import tensorflow.keras as keras\n",
    "from noise_generator.noisegen import NoiseHandling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_process.fft import stfft, normalizer, get_highest_rows, cut_fft_image, fit_image_length, expand_image_dims, train_img_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_velocity = keras.models.load_model('saved_model_velocity')\n",
    "model_regression = keras.models.load_model('saved_model_regression')\n",
    "model_categorical = keras.models.load_model('saved_model_categorical_right_align')\n",
    "TRAINING_IMAGE_DIMENSIONS = (5, 1400)\n",
    "NODGE_IMAGE_PIXEL_AMOUNT = 5 #Push the image to the left to adjust for incorrect position prediction\n",
    "CATEGORICAL_IMAGE_CROPPED_WIDTH = TRAINING_IMAGE_DIMENSIONS[1] - 1250 #Cropped with during traing of categorical prediction model\"\n",
    "FFT_JUMP = 64\n",
    "MEAN_TEMPO_OF_TRAINING_DATA = (18 + 25) / 2 # The mean tempo of the training data tempis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, width=300):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, width)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# insert an image into an empty image at start and en position\n",
    "def insert_image(empty_image, image, start_pos, end_pos):\n",
    "    empty_image[:, start_pos:end_pos] = image\n",
    "    return empty_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_AUDIO_FILE_NAME = 'training_data/AUDIO18/ABOHLVI_03000_18_000.wav'\n",
    "ORIG_AUDIO_FILE_NAME_2 = 'training_data/AUDIO18/AIAMOMCESHBBK_09900_18_000.wav'\n",
    "\n",
    "SampleRate, signal = wavfile.read(ORIG_AUDIO_FILE_NAME_2)\n",
    "\n",
    "length = signal.shape[0] / SampleRate\n",
    "\n",
    "print(signal.shape)\n",
    "print(SampleRate)\n",
    "print('length:', length, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnoise=NoiseHandling()\n",
    "Cnoise.SetFrequencies(6000,2200,200)\n",
    "Cnoise.noise_rng\n",
    "signal_to_noise_ratio_db = 0 # From 0 = no noise to -15 = significant noise\n",
    "# INFO:  table of SNRdb vs. digit in version\\n\",\n",
    "# ver \\t 0   1   2  3  4\\n\",\n",
    "# SNRdB   30  10  5  2  0\\n\",\n",
    "signal=signal/np.amax(signal)\n",
    "signal_noise, someNoise= Cnoise.addNoise(signal, signal_to_noise_ratio_db)\n",
    "img_noise = train_img_generate(signal_noise, FFT_JUMP)\n",
    "img = train_img_generate(signal, FFT_JUMP)\n",
    "\n",
    "show_image(img, 300)\n",
    "show_image(img_noise, 300)\n",
    "print(signal[:200])\n",
    "print(signal_noise[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velocity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_prediction = (model_velocity(expand_image_dims(img_noise))).numpy()[0][0] * 100\n",
    "velocity_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new image with mean tempo of training data based on velocity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_jump_tempo_coefficient = (MEAN_TEMPO_OF_TRAINING_DATA / velocity_prediction)\n",
    "rescaled_jump = FFT_JUMP * fft_jump_tempo_coefficient\n",
    "img_noise_rescaled = train_img_generate(signal_noise, rescaled_jump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check n-px ahead and determine signal activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img_noise_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_50_cut=img_noise_rescaled[:,:70]\n",
    "image_50_cut_copy = image_50_cut.copy()\n",
    "# image_50_cut_copy[:,50:100] = 0\n",
    "\n",
    "def determine_activity(img):\n",
    "    return np.sum(img, axis=1)\n",
    "   \n",
    "show_image(image_50_cut_copy)\n",
    "sorted_row_sums = determine_activity(image_50_cut_copy)\n",
    "sorted_row_sums\n",
    "mean_lowest_rows = (sorted_row_sums[0] + sorted_row_sums[3] + sorted_row_sums[4]) / 3\n",
    "mean_highest_rows = (sorted_row_sums[1] + sorted_row_sums[2]) / 2\n",
    "\n",
    "diff = abs(mean_lowest_rows - mean_highest_rows)\n",
    "# # return True if diff > 2 else False\n",
    "sorted_row_sums, diff / (mean_highest_rows / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression prediction to obtain first letter end position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_position = model_regression(expand_image_dims(img_noise_rescaled)).numpy()[0][0] * 1400\n",
    "show_image(img_noise_rescaled, width=200)\n",
    "first_letter_position = first_letter_position + NODGE_IMAGE_PIXEL_AMOUNT\n",
    "first_letter_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare image for categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = int(CATEGORICAL_IMAGE_CROPPED_WIDTH - first_letter_position)\n",
    "image_with_categorical_cropped = insert_image(\n",
    "    empty_image=np.zeros(TRAINING_IMAGE_DIMENSIONS), \n",
    "    image=img_noise_rescaled[:,:int(first_letter_position)], \n",
    "    start_pos=start_position, \n",
    "    end_pos= int(first_letter_position) + start_position\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_prediction = model_categorical(expand_image_dims(image_with_categorical_cropped))\n",
    "show_image(image_with_categorical_cropped, width=200)\n",
    "print('categorical prediction: ', np.argmax(categorical_prediction))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be0503bf1d8a1ee3ca0077be831d95fbcddd9686f11808f41fa1809452b7e6ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('newenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
