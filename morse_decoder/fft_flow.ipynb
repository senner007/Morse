{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import tensorflow.keras as keras\n",
    "from noise_generator.noisegen import NoiseHandling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from audio_process.fft import expand_image_dims, train_img_generate\n",
    "from Image_Generator_helpers import  DataSets, set_paths, global_path\n",
    "from data_filters import min_n_letters_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_velocity = keras.models.load_model('saved_model_velocity_raw_23')\n",
    "model_regression = keras.models.load_model('saved_model_regresssion_raw')\n",
    "model_categorical = keras.models.load_model('saved_model_categorical_raw')\n",
    "model_binary = keras.models.load_model('saved_model_raw_binary')\n",
    "TRAINING_IMAGE_DIMENSIONS = (5, 1400)\n",
    "NODGE_IMAGE_PIXEL_AMOUNT = 5 #Push the image to the left to adjust for incorrect position prediction\n",
    "CATEGORICAL_IMAGE_CROPPED_WIDTH = TRAINING_IMAGE_DIMENSIONS[1] - 1250 #Cropped with during traing of categorical prediction model\"\n",
    "FFT_JUMP = 64\n",
    "MEAN_TEMPO_OF_TRAINING_DATA = (18 + 25) / 2 # The mean tempo of the training data tempis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, width, position = []):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, width)\n",
    "    if len(position) != 0:\n",
    "        plt.xticks(position)    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# insert an image into an empty image at start and en position\n",
    "def insert_image(empty_image, image, start_pos, end_pos):\n",
    "    empty_image[:, start_pos:end_pos] = image\n",
    "    return empty_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnoise=NoiseHandling()\n",
    "Cnoise.SetFrequencies(6000,2200,200)\n",
    "Cnoise.noise_rng\n",
    "# From 0 = no noise to -15 = significant noise\n",
    "# INFO:  table of SNRdb vs. digit in version\\n\",\n",
    "# ver \\t 0   1   2  3  4\\n\",\n",
    "# SNRdB   30  10  5  2  0\\n\",\n",
    "\n",
    "def apply_noise(signal, signal_to_noise_ratio_db):\n",
    "    signal_noise, some_noise = Cnoise.addNoise(signal, signal_to_noise_ratio_db)\n",
    "    return signal_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_obj = DataSets(set_paths, global_path, [min_n_letters_raw(3)])\n",
    "# set_obj.csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # start_time = time.time()\n",
    "\n",
    "# random_sets = [set_obj.get_random() for n in range(128)]\n",
    "# random_signals = [set_obj.get_item(random_set) for random_set in random_sets]\n",
    "# signals_shiftet = [np.insert(signal, 0, np.zeros(0), axis=0) for signal in random_signals] ## prepend with 12840 zeros to align with image pixel 200\n",
    "# signal_noises = [apply_noise(signal, 5) for signal in signals_shiftet]\n",
    "# images_noise = [train_img_generate(signal_noise, FFT_JUMP) for signal_noise in signal_noises]\n",
    "\n",
    "# print(type(images_noise[0]))\n",
    "\n",
    "# # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# for idx,img in enumerate(images_noise):\n",
    "#     print(f\"Word nr : {idx}\")\n",
    "#     print(random_sets[idx].csv_row.WORD)\n",
    "#     print(\"First image:\")\n",
    "#     show_image(img, 0, 250)\n",
    "#     print(img)\n",
    "#     if (idx > 5):\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_AUDIO_FILE_NAME = 'training_data/MorseTrainSet_23/AUDIO23/BOPAEWITAVZSEE_10400_23_010.wav'\n",
    "# ORIG_AUDIO_FILE_NAME_2 = 'training_data/AUDIO18/AIAMOMCESHBBK_09900_18_000.wav'\n",
    "\n",
    "SampleRate, signal = wavfile.read(ORIG_AUDIO_FILE_NAME)\n",
    "\n",
    "length = signal.shape[0] / SampleRate\n",
    "\n",
    "print(signal.shape)\n",
    "print(SampleRate)\n",
    "print('length:', length, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.float32(signal)\n",
    "max = np.max(signal)\n",
    "signal = signal / max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_to_noise_ratio_db = 30 # From 0 = no noise to -15 = significant noise\n",
    "signal_noise = apply_noise(signal, signal_to_noise_ratio_db)\n",
    "img_noise = train_img_generate(signal_noise, FFT_JUMP)\n",
    "\n",
    "show_image(img_noise, 1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velocity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_prediction = (model_velocity(expand_image_dims(img_noise))).numpy()[0][0] * 100\n",
    "velocity_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new image with mean tempo of training data based on velocity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_jump_tempo_coefficient = (MEAN_TEMPO_OF_TRAINING_DATA / velocity_prediction)\n",
    "rescaled_jump = FFT_JUMP * fft_jump_tempo_coefficient\n",
    "img_noise_rescaled = train_img_generate(signal_noise, rescaled_jump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check n-px ahead and determine signal activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img_noise_rescaled, 1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression prediction to obtain first letter end position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_position = model_regression(expand_image_dims(img_noise_rescaled)).numpy()[0][0] * 1400\n",
    "show_image(img_noise_rescaled, 200, [int(first_letter_position)])\n",
    "first_letter_position_nodged = first_letter_position + NODGE_IMAGE_PIXEL_AMOUNT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare image for categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = int(CATEGORICAL_IMAGE_CROPPED_WIDTH - first_letter_position_nodged)\n",
    "image_with_categorical_cropped = insert_image(\n",
    "    empty_image=np.zeros([5,150]), \n",
    "    image=img_noise_rescaled[:,:int(first_letter_position_nodged)], \n",
    "    start_pos=start_position, \n",
    "    end_pos= int(first_letter_position_nodged) + start_position\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_with_categorical_cropped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "categorical_prediction = model_categorical(expand_image_dims(image_with_categorical_cropped))\n",
    "show_image(image_with_categorical_cropped, width=200)\n",
    "print('categorical prediction: ', np.argmax(categorical_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def left_shift_image(image, pos):\n",
    "    print(pos)\n",
    "    empty_image = np.zeros([5, 1400])\n",
    "    empty_image[:, 0: 1400 - pos] = image[:, pos: 1400]\n",
    "    return empty_image\n",
    "\n",
    "shifted_image = left_shift_image(img_noise_rescaled, int(first_letter_position_nodged))\n",
    "\n",
    "show_image(shifted_image, 1400)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be0503bf1d8a1ee3ca0077be831d95fbcddd9686f11808f41fa1809452b7e6ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
