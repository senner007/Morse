{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from noise_generator.noisegen import NoiseHandling\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from audio_process.fft import expand_image_dims, train_img_generate\n",
    "from Image_Generator_helpers import  DataSets, set_paths, global_path\n",
    "from data_filters import min_n_letters_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_velocity = keras.models.load_model('saved_model_velocity')\n",
    "model_regression = keras.models.load_model('saved_model_regression')\n",
    "model_categorical = keras.models.load_model('saved_model_categorical_right_align')\n",
    "TRAINING_IMAGE_DIMENSIONS = (5, 1400)\n",
    "NODGE_IMAGE_PIXEL_AMOUNT = 5 #Push the image to the left to adjust for incorrect position prediction\n",
    "CATEGORICAL_IMAGE_CROPPED_WIDTH = TRAINING_IMAGE_DIMENSIONS[1] - 1250 #Cropped with during traing of categorical prediction model\"\n",
    "FFT_JUMP = 64\n",
    "MEAN_TEMPO_OF_TRAINING_DATA = (18 + 25) / 2 # The mean tempo of the training data tempis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, start=0, width=300):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(start, width)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# insert an image into an empty image at start and en position\n",
    "def insert_image(empty_image, image, start_pos, end_pos):\n",
    "    empty_image[:, start_pos:end_pos] = image\n",
    "    return empty_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnoise=NoiseHandling()\n",
    "Cnoise.SetFrequencies(6000,2200,200)\n",
    "# Cnoise.noise_rng\n",
    "# From 0 = no noise to -15 = significant noise\n",
    "# INFO:  table of SNRdb vs. digit in version\\n\",\n",
    "# ver \\t 0   1   2  3  4\\n\",\n",
    "# SNRdB   30  10  5  2  0\\n\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_obj = DataSets(set_paths, global_path, [min_n_letters_raw(3)])\n",
    "set_obj.csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_noise(signal, signal_to_noise_ratio_db):\n",
    "\n",
    "    signal_noise, some_noise = Cnoise.addNoise(signal, signal_to_noise_ratio_db)\n",
    "    return signal_noise\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "random_sets = [set_obj.get_random() for n in range(128)]\n",
    "random_signals = [set_obj.get_item(random_set) for random_set in random_sets]\n",
    "signals_shiftet = [np.insert(signal, 0, np.zeros(0), axis=0) for signal in random_signals] ## prepend with 12840 zeros to align with image pixel 200\n",
    "signal_noises = [apply_noise(signal, 5) for signal in signals_shiftet]\n",
    "images_noise = [train_img_generate(signal_noise, FFT_JUMP) for signal_noise in signal_noises]\n",
    "\n",
    "print(type(images_noise[0]))\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "for idx,img in enumerate(images_noise):\n",
    "    print(f\"Word nr : {idx}\")\n",
    "    print(random_sets[idx].csv_row.WORD)\n",
    "    print(\"First image:\")\n",
    "    show_image(img, 0, 250)\n",
    "    print(img)\n",
    "    if (idx > 5):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velocity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_prediction = (model_velocity(expand_image_dims(images_noise[0]))).numpy()[0][0] * 100\n",
    "velocity_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate new image with mean tempo of training data based on velocity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_jump_tempo_coefficient = (MEAN_TEMPO_OF_TRAINING_DATA / velocity_prediction)\n",
    "rescaled_jump = FFT_JUMP * fft_jump_tempo_coefficient\n",
    "img_noise_rescaled = train_img_generate(signal_noises[0], rescaled_jump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check n-px ahead and determine signal activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img_noise_rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression prediction to obtain first letter end position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_letter_position = model_regression(expand_image_dims(img_noise_rescaled)).numpy()[0][0] * 1400\n",
    "show_image(img_noise_rescaled, width=200)\n",
    "first_letter_position = first_letter_position + NODGE_IMAGE_PIXEL_AMOUNT\n",
    "first_letter_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare image for categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = int(CATEGORICAL_IMAGE_CROPPED_WIDTH - first_letter_position)\n",
    "image_with_categorical_cropped = insert_image(\n",
    "    empty_image=np.zeros(TRAINING_IMAGE_DIMENSIONS), \n",
    "    image=img_noise_rescaled[:,:int(first_letter_position)], \n",
    "    start_pos=start_position, \n",
    "    end_pos= int(first_letter_position) + start_position\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_prediction = model_categorical(expand_image_dims(image_with_categorical_cropped))\n",
    "show_image(image_with_categorical_cropped, width=200)\n",
    "print('categorical prediction: ', np.argmax(categorical_prediction))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddce95701716284d8751d5796858f7ca5e76f20d028bc4aeb8f12865d04c55c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
