{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Conv2D, Conv1D, MaxPooling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras, config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs Available: \", len(config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_process.image_preprocessors import add_noise_randomly, cut_and_center, cut_and_right_align, shift_randomly, Preprocess\n",
    "from data_filters import tempo_interval, take_percent\n",
    "# Global settings\n",
    "TEST_SPLIT_SIZE = 0.80\n",
    "VALIDATION_SPLIT_SIZE = 0.90\n",
    "IMAGE_TARGET_SIZE = (5, 1400, 1)\n",
    "IMAGE_CROP_END_WIDTH = 1250\n",
    "IMAGE_CROPPED_WIDTH = IMAGE_TARGET_SIZE[1] - IMAGE_CROP_END_WIDTH\n",
    "BATCH_SIZE =  128\n",
    "CATEGORIES = 26\n",
    "LETTER_END_POSITION = \"P1\"\n",
    "IMAGE_PREPOCESSORS = [\n",
    "    {\"func\": cut_and_right_align, \"params\" : [IMAGE_CROPPED_WIDTH] },\n",
    "    {\"func\": shift_randomly, \"params\" : [-10, 0]},\n",
    "    {\"func\": add_noise_randomly, \"params\":  [0, 15] }\n",
    "    # Preprocess(cut_and_right_align, [IMAGE_CROPPED_WIDTH]), \n",
    "    # Preprocess(shift_randomly, [-10, 0]), \n",
    "    # Preprocess(add_noise_randomly, [0, 15])\n",
    "]\n",
    "MASKS = [\n",
    "    {\"func\" : tempo_interval, \"params\" : [18, 25]}, \n",
    "    {\"func\": take_percent, \"params\": 100}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from morse_helpers import create_sets\n",
    "from morse_label_funcs import  labels_to_one_hot_positions_categorical, letter_n_to_index, position_regression\n",
    "\n",
    "(image_fnames, morse_labels) = create_sets(\n",
    "    [\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_012/\", 'wordsMatrices_18_012', \"Words_18_012.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_021/\", 'wordsMatrices_18_021', \"Words_18_021.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_022/\", 'wordsMatrices_18_022', \"Words_18_022.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_111/\", 'wordsMatrices_18_111', \"Words_18_111.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_222/\", 'wordsMatrices_18_222', \"Words_18_222.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_301/\", 'wordsMatrices_18_301', \"Words_18_301.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_320/\", 'wordsMatrices_18_320', \"Words_18_320.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_411/\", 'wordsMatrices_18_411', \"Words_18_411.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_410/\", 'wordsMatrices_18_410', \"Words_18_410.csv\"],\n",
    "        [\"./training_data/MorseTrainSet_18/GEN18_VER_402/\", 'wordsMatrices_18_402', \"Words_18_402.csv\"],\n",
    "\n",
    "    ], \n",
    "    IMAGE_TARGET_SIZE,\n",
    "    [position_regression, letter_n_to_index],\n",
    "    letter_n=LETTER_END_POSITION,\n",
    "    overwrite_images=False,\n",
    "    masks=MASKS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat label arrays for shuffling\n",
    "morse_labels_concat = np.array([morse_labels[0], morse_labels[1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve me\n",
    "def labels_to_one_hot(labels):\n",
    "    label_letters = labels[1].astype(\"int\")\n",
    "    labels_one_hot = np.zeros((label_letters.size, CATEGORIES))\n",
    "    labels_one_hot[np.arange(label_letters.size),label_letters] = 1\n",
    "    return labels_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_helpers import create_all_sets\n",
    "train, labels, train_validation, labels_validation, train_test, labels_test = create_all_sets(\n",
    "    image_fnames, morse_labels_concat, TEST_SPLIT_SIZE, VALIDATION_SPLIT_SIZE, shuffle_before_test_split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_generators.image_generator import Image_Generator\n",
    "\n",
    "training_batch_generator = Image_Generator(train, labels, BATCH_SIZE, IMAGE_TARGET_SIZE, IMAGE_PREPOCESSORS, labels_to_one_hot)\n",
    "validation_batch_generator = Image_Generator(train_validation, labels_validation, BATCH_SIZE, IMAGE_TARGET_SIZE, IMAGE_PREPOCESSORS, labels_to_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual block\n",
    "def get_addblock(x, kernelsize, filters):\n",
    "    fx = layers.Conv2D(filters, kernelsize, activation='relu', padding='same')(x)\n",
    "    fx = layers.BatchNormalization()(fx)\n",
    "    fx = layers.Conv2D(filters, kernelsize, padding='same')(fx)\n",
    "    out = layers.Add()([x,fx])\n",
    "    out = layers.ReLU()(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_catg(input_layer):\n",
    "    \n",
    "    x = keras.layers.Cropping2D(cropping=((0, 0), (0,IMAGE_CROP_END_WIDTH)), data_format=None)(input_layer)\n",
    "\n",
    "    x = get_addblock(x, (3,5), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "    x = get_addblock(x, (3,7), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "    x = get_addblock(x, (3,3), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "    x = get_addblock(x, (3,3), 8)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "  \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_layer    = Input(shape=IMAGE_TARGET_SIZE)\n",
    "conv_model_flattened = conv_model_catg(input_layer)\n",
    "output_layer_letter    = Dense(CATEGORIES, activation=\"softmax\")(conv_model_flattened)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer_letter)\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 2\n",
    "\n",
    "def fit_model(epochs):\n",
    "\t\n",
    "\t\n",
    "\tglobal init_epoch\n",
    "\thistory = model.fit(\n",
    "\t\t\t\t\t   training_batch_generator,\n",
    "\t                   steps_per_epoch = int(len(train) // BATCH_SIZE),\n",
    "\t                   epochs = epochs + init_epoch,\n",
    "\t\t\t\t\t   initial_epoch=init_epoch,\n",
    "\t                   verbose =1,\n",
    "\t                   validation_data = validation_batch_generator,\n",
    "\t                   validation_steps = int(len(train_validation) // BATCH_SIZE))\n",
    "\t\n",
    "\t\n",
    "\tinit_epoch += epochs\n",
    "\treturn history\n",
    "\n",
    "history = fit_model(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"saved_model_categorical_right_align\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, width=300):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, width)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PREPROCESSORS_TEST = [\n",
    "    {\"func\": cut_and_right_align, \"params\" : [IMAGE_CROPPED_WIDTH] },\n",
    "    {\"func\": shift_randomly, \"params\" : [-10, 0]},\n",
    "    {\"func\": add_noise_randomly, \"params\":  [0, 1] }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate test generator\n",
    "test_batch_generator = Image_Generator(train_test, labels_test, BATCH_SIZE, IMAGE_TARGET_SIZE, IMAGE_PREPROCESSORS_TEST, labels_to_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image from test generator\n",
    "\n",
    "t, l = test_batch_generator.__getitem__(0)\n",
    "show_image(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_deviating_predictions(generator, predictions):\n",
    "    categorical_differences = []\n",
    "    indexer = 0\n",
    "\n",
    "    for imgs_batch, labels_batch in generator:\n",
    "\n",
    "        for i in range(len(imgs_batch)):\n",
    "\n",
    "            catg_pred = np.argmax(predictions[indexer])\n",
    "            catg_test_label = np.argmax(labels_batch[i])\n",
    "\n",
    "            if catg_pred != catg_test_label:\n",
    "\n",
    "                categorical_differences.append([catg_pred, catg_test_label, imgs_batch[i], predictions[indexer]])\n",
    "\n",
    "            indexer += 1\n",
    "\n",
    "    return categorical_differences\n",
    "\n",
    "\n",
    "categorical_differences  = get_deviating_predictions(test_batch_generator, predictions)\n",
    "\n",
    "print(\"Total label predictions: \", len(predictions))\n",
    "print(\"Total label predictions incorrect: \", len(categorical_differences))\n",
    "print(\"Label predictions percentage incorrect\", round( (len(categorical_differences) / len(predictions) * 100), 4), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = model.evaluate(test_batch_generator)\n",
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morse_label_funcs import code_number\n",
    "print(\"Incorrect predictions:\")\n",
    "print(\"----------------------------------------------------------------------------------------\")\n",
    "for idx, diff in enumerate(categorical_differences):\n",
    "\n",
    "    if idx > 5:\n",
    "        break\n",
    "\n",
    "    pred, correct, img, one_hot = diff\n",
    "\n",
    "    print('All prediction scores:')\n",
    "    print(np.round(one_hot, 2))\n",
    "\n",
    "    print('Prediction:', pred, code_number[pred])\n",
    "    print('Correct:', correct, code_number[correct])\n",
    "    show_image(img)\n",
    "    print(\"----------------------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be0503bf1d8a1ee3ca0077be831d95fbcddd9686f11808f41fa1809452b7e6ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('newenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
