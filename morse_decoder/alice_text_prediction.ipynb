{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import tensorflow.keras as keras\n",
    "from noise_generator.noisegen import NoiseHandling\n",
    "from morse_label_funcs import code_number\n",
    "import time\n",
    "from audio_process.fft import expand_image_dims, train_img_generate, SIGNAL_TO_PIXEL_CONSTANT\n",
    "from Image_Generator_helpers import  DataSets, set_paths, global_path\n",
    "from data_filters import min_n_letters_raw, position_labels_de_normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_velocity = keras.models.load_model('saved_model_velocity_raw')\n",
    "model_regression = keras.models.load_model('saved_model_regresssion_raw_low_tempo_5')\n",
    "model_categorical = keras.models.load_model('saved_model_categorical_right_align_low_tempo')\n",
    "model_binary = keras.models.load_model('saved_model_raw_binary_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_IMAGE_DIMENSIONS = (5, 1400)\n",
    "NODGE_IMAGE_PIXEL_AMOUNT = 6 #Push the image to the left to adjust for incorrect position prediction\n",
    "CATEGORICAL_IMAGE_CROPPED_WIDTH = TRAINING_IMAGE_DIMENSIONS[1] - 1250 #Cropped with during traing of categorical prediction model\"\n",
    "FFT_JUMP = 64\n",
    "MEAN_TEMPO_OF_TRAINING_DATA = (16 + 22) / 2 # The mean tempo of the training data tempis \n",
    "SIGNAL_LENGTH_MULTIPLIER: int = 200\n",
    "SIGNAL_LENGTH =  SIGNAL_TO_PIXEL_CONSTANT * SIGNAL_LENGTH_MULTIPLIER\n",
    "ALICE_TEXT = \"Alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do once or twice she had peeped into the book her sister was reading but it had no pictures or conversations in it and what is the use of a book thought Alice without pictures or conversations So she was considering in her own mind as well as she could for the hot day made her feel very sleepy and stupid whether the pleasure of making a daisy chain would be worth the trouble of getting up and picking the daisies when suddenly a White Rabbit with pink eyes ran close by her\"\n",
    "ALICE_CORRECT: str = ALICE_TEXT.strip().replace(\" \", \"\").lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_AUDIO_FILE_NAME = 'training_data/MorseTrainSet_23/AUDIO23/BOPAEWITAVZSEE_10400_23_010.wav'\n",
    "ORIG_AUDIO_FILE_NAME_2 = 'training_data/MorseTrainSet_23/AUDIO23/ZBGLAQEMPZZNBNA_14400_23_021.wav'\n",
    "ALICE = 'Alice_audio/Alice_30_000.wav'\n",
    "ALICE_001 = 'Alice_audio/Alice_30_001.wav'\n",
    "ALICE_002 = 'Alice_audio/Alice_30_002.wav'\n",
    "ALICE_020 = 'Alice_audio/Alice_30_020.wav'\n",
    "ALICE_021 = 'Alice_audio/Alice_30_012.wav'\n",
    "ALICE_022 = 'Alice_audio/Alice_30_022.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noise_handling = NoiseHandling()\n",
    "noise_handling.SetFrequencies(6000,2200,200)\n",
    "# From 0 = no noise to -15 = significant noise\n",
    "# INFO:  table of SNRdb vs. digit in version\\n\",\n",
    "# ver \\t 0   1   2  3  4\\n\",\n",
    "# SNRdB   30  10  5  2  0\\n\",\n",
    "\n",
    "def apply_noise(signal, signal_to_noise_ratio_db):\n",
    "    signal_noise, some_noise = noise_handling.addNoise(signal, signal_to_noise_ratio_db)\n",
    "    return signal_noise\n",
    "\n",
    "# insert an image into an empty image at start and en position\n",
    "def insert_image(empty_image, image, start_pos, end_pos):\n",
    "    empty_image[:, start_pos:end_pos] = image\n",
    "    return empty_image\n",
    "\n",
    "def predict_velocity(img):\n",
    "    return (model_velocity(expand_image_dims(img))).numpy()[0][0] * 100\n",
    "\n",
    "def rescale_fft(velocity_prediction, fft_jump, mean_tempo_of_training_velocity):\n",
    "    return fft_jump * (mean_tempo_of_training_velocity / velocity_prediction)\n",
    "\n",
    "def left_shift_image(img, shift):\n",
    "    shift = int(shift)\n",
    "    shifted_left = np.pad(img, [(0,0),(0,abs(shift))], mode='constant')[:, abs(shift): img.shape[1] + abs(shift)]\n",
    "    return shifted_left\n",
    "\n",
    "def show_image(img, width, position = [], title=\"\"):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, width)\n",
    "    if len(position) != 0:\n",
    "        plt.xticks(position)    \n",
    "    plt.imshow(img)\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "def get_signal(wav):\n",
    "    SampleRate, signal = wavfile.read(wav)\n",
    "    # length = signal.shape[0] / SampleRate\n",
    "\n",
    "    signal = np.float32(signal)\n",
    "    signal = signal / np.max(signal)\n",
    "    return signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = get_signal(ALICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "signal_to_noise_ratio_db = 3 # From 0 = no noise to -15 = significant noise\n",
    "print(\"Noise level: \", signal_to_noise_ratio_db)\n",
    "signal_noise = apply_noise(signal, signal_to_noise_ratio_db)\n",
    "img_noise = train_img_generate(signal_noise, FFT_JUMP, SIGNAL_LENGTH)\n",
    "velocity_prediction = predict_velocity(img_noise[:, :1400])\n",
    "print(\"Velocity prediction: \" , velocity_prediction)\n",
    "rescaled_fft_jump = rescale_fft(velocity_prediction, FFT_JUMP, MEAN_TEMPO_OF_TRAINING_DATA)\n",
    "img_noise_rescaled = train_img_generate(signal_noise, rescaled_fft_jump, SIGNAL_LENGTH)\n",
    "\n",
    "rescaled_velocity_prediction = predict_velocity(img_noise_rescaled[:, :1400])\n",
    "print(\"Rescaled Velocity prediction: \", rescaled_velocity_prediction)\n",
    "\n",
    "show_image(img_noise_rescaled, 200, title=\"Starting image...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Correct: \", ALICE_CORRECT)\n",
    "print(\"Correct length: \", len(ALICE_CORRECT))\n",
    "\n",
    "signal_not_found_count: int = 0\n",
    "letters = []\n",
    "signal_presence_images = []\n",
    "img_noise_rescaled_images = []\n",
    "image_with_categorical_cropped_images = []\n",
    "DEBUG = True\n",
    "\n",
    "def letter_sequence(img_noise_rescaled):\n",
    "\n",
    "    img_noise_rescaled_images.append(img_noise_rescaled)\n",
    "    signal_presence_image = img_noise_rescaled[:, :400]\n",
    "    signal_presence_images.append(signal_presence_image)\n",
    "    signal_presence = model_binary(expand_image_dims(signal_presence_image)).numpy()[0][0]\n",
    "\n",
    "    if (signal_presence < 0.5):\n",
    "        global signal_not_found_count\n",
    "        signal_not_found_count += 1 \n",
    "        if (signal_not_found_count > 15): # return if signal not found after n times\n",
    "            return False\n",
    "\n",
    "        img_noise_rescaled = left_shift_image(img_noise_rescaled, 45)\n",
    "        return letter_sequence(img_noise_rescaled)\n",
    "       \n",
    "    signal_not_found_count = 0 # reset signal not found counter\n",
    "    first_letter_position = model_regression(expand_image_dims(img_noise_rescaled[:,:400])).numpy()[0][0]\n",
    "    first_letter_position = position_labels_de_normalizer(first_letter_position)\n",
    "    first_letter_position_nodged = first_letter_position + NODGE_IMAGE_PIXEL_AMOUNT\n",
    "\n",
    "    start_position = int(CATEGORICAL_IMAGE_CROPPED_WIDTH - first_letter_position_nodged)\n",
    "\n",
    "    # Create the categorical prediction image\n",
    "    image_with_categorical_cropped = insert_image(\n",
    "        empty_image=np.zeros([5,CATEGORICAL_IMAGE_CROPPED_WIDTH]), \n",
    "        image=img_noise_rescaled[:,:int(first_letter_position_nodged)], \n",
    "        start_pos=start_position, \n",
    "        end_pos= int(first_letter_position_nodged) + start_position\n",
    "    )\n",
    "\n",
    "    image_with_categorical_cropped_images.append(image_with_categorical_cropped)\n",
    "    categorical_prediction = model_categorical(expand_image_dims(image_with_categorical_cropped))\n",
    "    letters.append(code_number[np.argmax(categorical_prediction)])\n",
    "\n",
    "    \n",
    "    if (DEBUG == True):\n",
    "        list_length = len(letters) -1\n",
    "        prediction_current_letter = letters[list_length]\n",
    "        correct_current_letter = list(ALICE_CORRECT)[list_length]\n",
    "        if (prediction_current_letter  !=  correct_current_letter): # Debug when failed\n",
    "            print(\"list position: \", list_length)\n",
    "            print(\"Current prediction progress: \", \"\". join(letters))\n",
    "            title = f'Categorical : Prediction - {prediction_current_letter} - Correct: {correct_current_letter}'\n",
    "            show_image(image_with_categorical_cropped, 150, title=title)\n",
    "            show_image(img_noise_rescaled_images[-1], 400, title=\"Current main image\")\n",
    "            show_image(img_noise_rescaled_images[-2], 400, title=\"Previous main image\")\n",
    "            show_image(image_with_categorical_cropped_images[-2], 150, title=\"Categorical previous\")\n",
    "            return False\n",
    "   \n",
    "    shifted_image = left_shift_image(img_noise_rescaled, int(first_letter_position_nodged))\n",
    "\n",
    "    return letter_sequence(shifted_image)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "letter_sequence(img_noise_rescaled)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Total time (seconds): \", elapsed_time)\n",
    "\n",
    "prediction_joined = \"\". join(letters)\n",
    "print(\"Prediction: \", prediction_joined)\n",
    "print(\"Prediction length: \", len(prediction_joined))\n",
    "\n",
    "print(\"Prediction success: \", prediction_joined.strip() == ALICE_CORRECT.strip())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddce95701716284d8751d5796858f7ca5e76f20d028bc4aeb8f12865d04c55c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
