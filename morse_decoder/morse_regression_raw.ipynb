{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, Conv2D, Conv1D, MaxPooling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras, config\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs Available: \", len(config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from image_process.image_preprocessors import add_noise, add_noise_randomly, shift_random_update_positions, shift_randomly_position_labels\n",
    "from data_filters import tempo_interval, take_percent\n",
    "# Global settings\n",
    "TEST_SPLIT_SIZE = 0.80\n",
    "VALIDATION_SPLIT_SIZE = 0.90\n",
    "IMAGE_TARGET_SIZE = (5, 1400, 1)\n",
    "BATCH_SIZE = 128\n",
    "EPOCH_SIZE = 500\n",
    "LETTER_END_POSITION = \"P1\"\n",
    "ADD_NOISE_RANDOMLY = [-2, 20]\n",
    "ADD_SIGNAL_INDENT_RANDOMLY = 12860\n",
    "SHIFT_MIN_MAX = [-200, -140]\n",
    "TEMPO_INTERVAL = [16, 22]\n",
    "IMAGE_PREPOCESSORS = [\n",
    "    {\"func\": shift_randomly_position_labels, \"params\" : SHIFT_MIN_MAX},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, width, position):\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.xlim(0, width)\n",
    "    plt.xticks(position)    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def normalize_output(n:int):\n",
    "    return position_labels_de_normalizer(n, max_position=set_obj.max_first_letter_position, min_position=set_obj.min_first_letter_position, shift_max=shift_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Image_Generator_helpers import  DataSets, set_paths, global_path,Random_Item\n",
    "from data_filters import tempo_interval_raw, position_labels_de_normalizer\n",
    "set_obj: DataSets = DataSets(set_paths, global_path, [tempo_interval_raw(TEMPO_INTERVAL)], [\"P1\", \"P2\", \"P3\", \"P4\"])\n",
    "set_obj.csv_files\n",
    "\n",
    "shift_max = abs(SHIFT_MIN_MAX[0] - SHIFT_MIN_MAX[1])\n",
    "\n",
    "def get_position_labels(random_items):\n",
    "    return [item.csv_row[LETTER_END_POSITION].values.astype(np.float64)[0] for item in random_items]\n",
    "\n",
    "def position_labels_normalizer(labels, set_obj: DataSets, random_items: list[Random_Item]): # reuse other de_normalizer function\n",
    "    return np.array([(label - set_obj.min_first_letter_position) / (set_obj.max_first_letter_position + shift_max - set_obj.min_first_letter_position) for label in labels]) # Store these parameters on json\n",
    "\n",
    "def letter_e_bias(dataFrame):\n",
    "    return dataFrame[\"WORD\"].apply(str).str.startswith(\"e\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_generators.image_generator import Image_Generator_RAW\n",
    "class Regression_Image_Generator:\n",
    "    def __init__(self, image_amount, image_preprocessors, noise_range):\n",
    "        self.generator = Image_Generator_RAW(\n",
    "            image_amount=image_amount,\n",
    "            set_obj= set_obj,\n",
    "            FFT_JUMP=64,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            image_target_size=IMAGE_TARGET_SIZE,\n",
    "            image_prepocessors=image_preprocessors,\n",
    "            noise_range=noise_range,\n",
    "            random_signal_indent=ADD_SIGNAL_INDENT_RANDOMLY,\n",
    "            label_func = get_position_labels,\n",
    "            label_post_process=position_labels_normalizer,\n",
    "            signal_cut_off=12860,\n",
    "            position_probability=[0,2]\n",
    "        )\n",
    "\n",
    "Train_Generator_Raw = Regression_Image_Generator(\n",
    "    image_amount=BATCH_SIZE * EPOCH_SIZE,\n",
    "    image_preprocessors=IMAGE_PREPOCESSORS,\n",
    "    noise_range=ADD_NOISE_RANDOMLY\n",
    ").generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, l = Train_Generator_Raw.__getitem__(0)\n",
    "\n",
    "# labels_de_normalized = normalize_output(l)\n",
    "\n",
    "# for idx,img in enumerate(t):\n",
    "#     print(\"label: \")\n",
    "#     pos = labels_de_normalized[idx]\n",
    "#     print(pos)\n",
    "#     print(img.shape)\n",
    "#     show_image(img, 200, [50, 200, pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model_position(input_layer):\n",
    "    x = keras.layers.Cropping2D(cropping=((0, 0), (0,200)), data_format=None)(input_layer)\n",
    "\n",
    "    x = Conv2D(90,(1,7), padding=\"same\",activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,1),padding=\"same\")(x)\n",
    "\n",
    "    x = Conv2D(90,(1,7),padding=\"same\",activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "\n",
    "    x = Conv2D(90,(1,5),padding=\"same\",activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "\n",
    "    x = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "\n",
    "    x = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "\n",
    "    x = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "\n",
    "    x = Conv2D(90,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(1,2),padding=\"same\")(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "input_layer = Input(shape=(5, 400, 1))\n",
    "conv_model_position_flattened = conv_model_position(input_layer)\n",
    "output_layer_position = Dense(1, name=\"regr\")(conv_model_position_flattened)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer_position)\n",
    "model.compile(loss=[\"mse\"], optimizer='adam', metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 5\n",
    "\n",
    "def fit_model(epochs):\n",
    "\t\n",
    "\tglobal init_epoch\n",
    "\thistory = model.fit(\n",
    "\t\tTrain_Generator_Raw,\n",
    "\t\tsteps_per_epoch = EPOCH_SIZE,\n",
    "\t\tepochs = epochs + init_epoch,\n",
    "\t\tinitial_epoch=init_epoch,\n",
    "\t\tverbose =1,\n",
    "\t\t# validation_data = validation_batch_generator,\n",
    "\t\t# validation_steps = int(len(train_validation) // BATCH_SIZE),\n",
    "\t\tworkers=12,\n",
    "\t\tuse_multiprocessing=True\n",
    "\t)\n",
    "\n",
    "\t\n",
    "\tinit_epoch += epochs\n",
    "\treturn history\n",
    "\n",
    "history = fit_model(num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from log_helpers.training_log import Training_Data_Log, print_name, json_to_file, get_deviating_predictions\n",
    "import inspect\n",
    "\n",
    "data_log = Training_Data_Log()\n",
    "data_log.model_config = model.to_json()\n",
    "data_log.model_config_method_string = [inspect.getsource(conv_model_position)]\n",
    "# data_log.training_sets = get_sets()\n",
    "# data_log.training_set_size = len(train)\n",
    "# data_log.validation_set_size = len(train_validation)\n",
    "# data_log.test_set_size = len(train_test)\n",
    "data_log.image_pre_processors = print_name(IMAGE_PREPOCESSORS)\n",
    "data_log.noise_added = ADD_NOISE_RANDOMLY\n",
    "# data_log.training_data_masks = print_name(MASKS)\n",
    "data_log.model_summary = model.summary()\n",
    "data_log.model_optimizer = str(type(model.optimizer))\n",
    "data_log.model_history = history.history\n",
    "data_log.model_history_final_epoch = {k: v[-1] for k, v in history.history.items()}\n",
    "data_log.total_epochs = init_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression_Results:\n",
    "    image_preprocessors_test = None\n",
    "    total_predictions = None\n",
    "    noise_level = None\n",
    "    difference_in_pixels = None\n",
    "    predictions_off_by_more_than_difference = None\n",
    "    predictions_incorrect_prercent = None\n",
    "    model_evaluation = None\n",
    "\n",
    "noise_levels = [[-2, 20], [0, 20]]\n",
    "result_array = []\n",
    "BATCHES_TESTING = 250\n",
    "pixel_difference = 3\n",
    "\n",
    "def regression_comparer(prediction, correct):\n",
    "    prediction = normalize_output(prediction)\n",
    "    correct = normalize_output(correct)\n",
    "    return abs(prediction[0] - correct) < pixel_difference\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "\n",
    "    test_batch_generator = Regression_Image_Generator(\n",
    "        image_amount=BATCH_SIZE * BATCHES_TESTING,\n",
    "        image_preprocessors=IMAGE_PREPOCESSORS,\n",
    "        noise_range=noise_level\n",
    "    ).generator\n",
    "\n",
    "    regression_differences  = get_deviating_predictions(test_batch_generator, model, regression_comparer)\n",
    "\n",
    "    evaluations = model.evaluate(test_batch_generator, verbose = 0)\n",
    "\n",
    "    results = Regression_Results()\n",
    "    results.total_predictions = BATCHES_TESTING * BATCH_SIZE\n",
    "    results.noise_level = noise_level\n",
    "    results.difference_in_pixels = pixel_difference\n",
    "    results.predictions_off_by_more_than_difference = len(regression_differences)\n",
    "    results.predictions_incorrect_prercent =len(regression_differences) / (BATCHES_TESTING * BATCH_SIZE) * 100\n",
    "    results.model_evaluation = evaluations\n",
    "\n",
    "    result_array.append(results.__dict__)\n",
    "\n",
    "    print(len(regression_differences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log.results = result_array\n",
    "print(data_log.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_to_file(\"logs/regression/regression_data_log_raw\", data_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, diff in enumerate(regression_differences):\n",
    "\n",
    "    if idx > 100:\n",
    "        break\n",
    "\n",
    "    pred, correct, img = diff\n",
    "\n",
    "    pred = normalize_output(pred)\n",
    "    correct = normalize_output(correct)\n",
    "\n",
    "    img_pred = img.copy()\n",
    "    img_correct = img.copy()\n",
    "\n",
    "    print('Prediction', round(pred[0]))\n",
    "    img_pred[:, round(int(pred))] = 1\n",
    "    show_image(img_pred, 300, [round(pred[0])])\n",
    "\n",
    "    print('Correct', round(correct))\n",
    "    img_correct[:, round(int(correct))] = 1\n",
    "    show_image(img_correct, 300, [round(pred[0])])\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be0503bf1d8a1ee3ca0077be831d95fbcddd9686f11808f41fa1809452b7e6ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
